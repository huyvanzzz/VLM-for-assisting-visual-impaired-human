{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.054758514949074584,
  "eval_steps": 500,
  "global_step": 500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0005475851494907458,
      "grad_norm": 0.923701286315918,
      "learning_rate": 8.000000000000001e-06,
      "loss": 2.2744,
      "step": 5
    },
    {
      "epoch": 0.0010951702989814916,
      "grad_norm": 0.7302889823913574,
      "learning_rate": 1.8e-05,
      "loss": 2.3953,
      "step": 10
    },
    {
      "epoch": 0.0016427554484722375,
      "grad_norm": 0.5717050433158875,
      "learning_rate": 2.8000000000000003e-05,
      "loss": 2.2327,
      "step": 15
    },
    {
      "epoch": 0.002190340597962983,
      "grad_norm": 0.7232187986373901,
      "learning_rate": 3.8e-05,
      "loss": 2.3731,
      "step": 20
    },
    {
      "epoch": 0.002737925747453729,
      "grad_norm": 0.9372161030769348,
      "learning_rate": 4.8e-05,
      "loss": 2.2132,
      "step": 25
    },
    {
      "epoch": 0.003285510896944475,
      "grad_norm": 0.9106276631355286,
      "learning_rate": 5.8e-05,
      "loss": 2.2769,
      "step": 30
    },
    {
      "epoch": 0.0038330960464352205,
      "grad_norm": 0.8363201022148132,
      "learning_rate": 6.800000000000001e-05,
      "loss": 2.2021,
      "step": 35
    },
    {
      "epoch": 0.004380681195925966,
      "grad_norm": 0.8099052309989929,
      "learning_rate": 7.800000000000001e-05,
      "loss": 2.0269,
      "step": 40
    },
    {
      "epoch": 0.004928266345416712,
      "grad_norm": 0.9944636821746826,
      "learning_rate": 8.800000000000001e-05,
      "loss": 1.8829,
      "step": 45
    },
    {
      "epoch": 0.005475851494907458,
      "grad_norm": 1.2323696613311768,
      "learning_rate": 9.8e-05,
      "loss": 1.8468,
      "step": 50
    },
    {
      "epoch": 0.006023436644398204,
      "grad_norm": 0.9476654529571533,
      "learning_rate": 0.00010800000000000001,
      "loss": 1.9386,
      "step": 55
    },
    {
      "epoch": 0.00657102179388895,
      "grad_norm": 1.4098447561264038,
      "learning_rate": 0.000118,
      "loss": 1.7038,
      "step": 60
    },
    {
      "epoch": 0.007118606943379696,
      "grad_norm": 1.2325670719146729,
      "learning_rate": 0.00012800000000000002,
      "loss": 1.659,
      "step": 65
    },
    {
      "epoch": 0.007666192092870441,
      "grad_norm": 1.5486595630645752,
      "learning_rate": 0.000138,
      "loss": 1.665,
      "step": 70
    },
    {
      "epoch": 0.008213777242361187,
      "grad_norm": 1.4226500988006592,
      "learning_rate": 0.000148,
      "loss": 1.5763,
      "step": 75
    },
    {
      "epoch": 0.008761362391851933,
      "grad_norm": 1.3975284099578857,
      "learning_rate": 0.00015800000000000002,
      "loss": 1.8189,
      "step": 80
    },
    {
      "epoch": 0.009308947541342679,
      "grad_norm": 1.5999573469161987,
      "learning_rate": 0.000168,
      "loss": 1.5687,
      "step": 85
    },
    {
      "epoch": 0.009856532690833425,
      "grad_norm": 1.5239871740341187,
      "learning_rate": 0.00017800000000000002,
      "loss": 1.5318,
      "step": 90
    },
    {
      "epoch": 0.01040411784032417,
      "grad_norm": 1.9403927326202393,
      "learning_rate": 0.000188,
      "loss": 1.3698,
      "step": 95
    },
    {
      "epoch": 0.010951702989814916,
      "grad_norm": 1.7858357429504395,
      "learning_rate": 0.00019800000000000002,
      "loss": 1.6737,
      "step": 100
    },
    {
      "epoch": 0.011499288139305662,
      "grad_norm": 1.427161455154419,
      "learning_rate": 0.00019997068845491517,
      "loss": 1.4096,
      "step": 105
    },
    {
      "epoch": 0.012046873288796408,
      "grad_norm": 1.481513261795044,
      "learning_rate": 0.00019993404902355917,
      "loss": 1.6306,
      "step": 110
    },
    {
      "epoch": 0.012594458438287154,
      "grad_norm": 1.361019492149353,
      "learning_rate": 0.00019989740959220313,
      "loss": 1.5504,
      "step": 115
    },
    {
      "epoch": 0.0131420435877779,
      "grad_norm": 1.411868691444397,
      "learning_rate": 0.00019986077016084713,
      "loss": 1.5682,
      "step": 120
    },
    {
      "epoch": 0.013689628737268646,
      "grad_norm": 1.6771917343139648,
      "learning_rate": 0.0001998241307294911,
      "loss": 1.5249,
      "step": 125
    },
    {
      "epoch": 0.014237213886759392,
      "grad_norm": 1.5097565650939941,
      "learning_rate": 0.00019978749129813506,
      "loss": 1.4376,
      "step": 130
    },
    {
      "epoch": 0.014784799036250136,
      "grad_norm": 1.5297003984451294,
      "learning_rate": 0.00019975085186677905,
      "loss": 1.6552,
      "step": 135
    },
    {
      "epoch": 0.015332384185740882,
      "grad_norm": 1.1463454961776733,
      "learning_rate": 0.00019971421243542302,
      "loss": 1.4423,
      "step": 140
    },
    {
      "epoch": 0.015879969335231628,
      "grad_norm": 2.125288248062134,
      "learning_rate": 0.00019967757300406698,
      "loss": 1.307,
      "step": 145
    },
    {
      "epoch": 0.016427554484722374,
      "grad_norm": 1.5903918743133545,
      "learning_rate": 0.00019964093357271095,
      "loss": 1.6059,
      "step": 150
    },
    {
      "epoch": 0.01697513963421312,
      "grad_norm": 1.3271065950393677,
      "learning_rate": 0.00019960429414135492,
      "loss": 1.3492,
      "step": 155
    },
    {
      "epoch": 0.017522724783703866,
      "grad_norm": 2.1793649196624756,
      "learning_rate": 0.0001995676547099989,
      "loss": 1.3608,
      "step": 160
    },
    {
      "epoch": 0.01807030993319461,
      "grad_norm": 1.274411916732788,
      "learning_rate": 0.00019953101527864288,
      "loss": 1.5418,
      "step": 165
    },
    {
      "epoch": 0.018617895082685357,
      "grad_norm": 1.5096458196640015,
      "learning_rate": 0.00019949437584728684,
      "loss": 1.4676,
      "step": 170
    },
    {
      "epoch": 0.019165480232176103,
      "grad_norm": 1.4591524600982666,
      "learning_rate": 0.00019945773641593084,
      "loss": 1.6743,
      "step": 175
    },
    {
      "epoch": 0.01971306538166685,
      "grad_norm": 2.23306941986084,
      "learning_rate": 0.0001994210969845748,
      "loss": 1.3192,
      "step": 180
    },
    {
      "epoch": 0.020260650531157595,
      "grad_norm": 1.3079930543899536,
      "learning_rate": 0.00019938445755321877,
      "loss": 1.6714,
      "step": 185
    },
    {
      "epoch": 0.02080823568064834,
      "grad_norm": 1.3222911357879639,
      "learning_rate": 0.00019934781812186276,
      "loss": 1.3639,
      "step": 190
    },
    {
      "epoch": 0.021355820830139087,
      "grad_norm": 1.2437527179718018,
      "learning_rate": 0.00019931117869050673,
      "loss": 1.5372,
      "step": 195
    },
    {
      "epoch": 0.021903405979629833,
      "grad_norm": 1.4097708463668823,
      "learning_rate": 0.00019927453925915072,
      "loss": 1.2604,
      "step": 200
    },
    {
      "epoch": 0.02245099112912058,
      "grad_norm": 1.5521143674850464,
      "learning_rate": 0.0001992378998277947,
      "loss": 1.4132,
      "step": 205
    },
    {
      "epoch": 0.022998576278611325,
      "grad_norm": 1.3385597467422485,
      "learning_rate": 0.00019920126039643866,
      "loss": 1.3393,
      "step": 210
    },
    {
      "epoch": 0.02354616142810207,
      "grad_norm": 1.5177115201950073,
      "learning_rate": 0.00019916462096508265,
      "loss": 1.4228,
      "step": 215
    },
    {
      "epoch": 0.024093746577592817,
      "grad_norm": 2.4036636352539062,
      "learning_rate": 0.00019912798153372662,
      "loss": 1.4687,
      "step": 220
    },
    {
      "epoch": 0.024641331727083562,
      "grad_norm": 1.4817503690719604,
      "learning_rate": 0.00019909134210237058,
      "loss": 1.2808,
      "step": 225
    },
    {
      "epoch": 0.02518891687657431,
      "grad_norm": 1.423327922821045,
      "learning_rate": 0.00019905470267101455,
      "loss": 1.1724,
      "step": 230
    },
    {
      "epoch": 0.025736502026065054,
      "grad_norm": 1.8105131387710571,
      "learning_rate": 0.00019901806323965852,
      "loss": 1.3154,
      "step": 235
    },
    {
      "epoch": 0.0262840871755558,
      "grad_norm": 1.9201974868774414,
      "learning_rate": 0.0001989814238083025,
      "loss": 1.4329,
      "step": 240
    },
    {
      "epoch": 0.026831672325046546,
      "grad_norm": 1.7772910594940186,
      "learning_rate": 0.00019894478437694648,
      "loss": 1.5892,
      "step": 245
    },
    {
      "epoch": 0.027379257474537292,
      "grad_norm": 1.34568190574646,
      "learning_rate": 0.00019890814494559044,
      "loss": 1.3771,
      "step": 250
    },
    {
      "epoch": 0.027926842624028038,
      "grad_norm": 1.5749460458755493,
      "learning_rate": 0.00019887150551423444,
      "loss": 1.3095,
      "step": 255
    },
    {
      "epoch": 0.028474427773518784,
      "grad_norm": 1.5490273237228394,
      "learning_rate": 0.0001988348660828784,
      "loss": 1.3362,
      "step": 260
    },
    {
      "epoch": 0.029022012923009526,
      "grad_norm": 1.4250160455703735,
      "learning_rate": 0.00019879822665152237,
      "loss": 1.3398,
      "step": 265
    },
    {
      "epoch": 0.029569598072500272,
      "grad_norm": 1.527358889579773,
      "learning_rate": 0.00019876158722016636,
      "loss": 1.1672,
      "step": 270
    },
    {
      "epoch": 0.030117183221991018,
      "grad_norm": 1.528719186782837,
      "learning_rate": 0.00019872494778881033,
      "loss": 1.2024,
      "step": 275
    },
    {
      "epoch": 0.030664768371481764,
      "grad_norm": 1.4808933734893799,
      "learning_rate": 0.00019868830835745432,
      "loss": 1.3913,
      "step": 280
    },
    {
      "epoch": 0.03121235352097251,
      "grad_norm": 1.524281620979309,
      "learning_rate": 0.0001986516689260983,
      "loss": 1.3525,
      "step": 285
    },
    {
      "epoch": 0.031759938670463256,
      "grad_norm": 1.1254044771194458,
      "learning_rate": 0.00019861502949474226,
      "loss": 1.2143,
      "step": 290
    },
    {
      "epoch": 0.032307523819954005,
      "grad_norm": 1.4765642881393433,
      "learning_rate": 0.00019857839006338622,
      "loss": 1.1303,
      "step": 295
    },
    {
      "epoch": 0.03285510896944475,
      "grad_norm": 1.4929672479629517,
      "learning_rate": 0.0001985417506320302,
      "loss": 1.4263,
      "step": 300
    },
    {
      "epoch": 0.0334026941189355,
      "grad_norm": 1.6962932348251343,
      "learning_rate": 0.00019850511120067415,
      "loss": 1.3503,
      "step": 305
    },
    {
      "epoch": 0.03395027926842624,
      "grad_norm": 1.5972434282302856,
      "learning_rate": 0.00019846847176931815,
      "loss": 1.2688,
      "step": 310
    },
    {
      "epoch": 0.03449786441791699,
      "grad_norm": 1.3901596069335938,
      "learning_rate": 0.00019843183233796211,
      "loss": 1.1151,
      "step": 315
    },
    {
      "epoch": 0.03504544956740773,
      "grad_norm": 1.2769930362701416,
      "learning_rate": 0.0001983951929066061,
      "loss": 1.4471,
      "step": 320
    },
    {
      "epoch": 0.03559303471689848,
      "grad_norm": 1.65082848072052,
      "learning_rate": 0.00019835855347525007,
      "loss": 1.2141,
      "step": 325
    },
    {
      "epoch": 0.03614061986638922,
      "grad_norm": 1.4298276901245117,
      "learning_rate": 0.00019832191404389404,
      "loss": 1.1921,
      "step": 330
    },
    {
      "epoch": 0.03668820501587997,
      "grad_norm": 1.4918714761734009,
      "learning_rate": 0.00019828527461253803,
      "loss": 1.405,
      "step": 335
    },
    {
      "epoch": 0.037235790165370715,
      "grad_norm": 1.3090577125549316,
      "learning_rate": 0.000198248635181182,
      "loss": 1.3818,
      "step": 340
    },
    {
      "epoch": 0.037783375314861464,
      "grad_norm": 1.0710124969482422,
      "learning_rate": 0.00019821199574982597,
      "loss": 1.0358,
      "step": 345
    },
    {
      "epoch": 0.03833096046435221,
      "grad_norm": 1.3572243452072144,
      "learning_rate": 0.00019817535631846996,
      "loss": 1.3124,
      "step": 350
    },
    {
      "epoch": 0.03887854561384295,
      "grad_norm": 1.3259793519973755,
      "learning_rate": 0.00019813871688711393,
      "loss": 1.3564,
      "step": 355
    },
    {
      "epoch": 0.0394261307633337,
      "grad_norm": 1.165297031402588,
      "learning_rate": 0.0001981020774557579,
      "loss": 1.1785,
      "step": 360
    },
    {
      "epoch": 0.03997371591282444,
      "grad_norm": 1.7511069774627686,
      "learning_rate": 0.00019806543802440186,
      "loss": 1.4783,
      "step": 365
    },
    {
      "epoch": 0.04052130106231519,
      "grad_norm": 1.3662772178649902,
      "learning_rate": 0.00019802879859304583,
      "loss": 1.3173,
      "step": 370
    },
    {
      "epoch": 0.04106888621180593,
      "grad_norm": 1.5592074394226074,
      "learning_rate": 0.00019799215916168982,
      "loss": 1.359,
      "step": 375
    },
    {
      "epoch": 0.04161647136129668,
      "grad_norm": 1.3349995613098145,
      "learning_rate": 0.0001979555197303338,
      "loss": 1.1968,
      "step": 380
    },
    {
      "epoch": 0.042164056510787425,
      "grad_norm": 1.5820469856262207,
      "learning_rate": 0.00019791888029897775,
      "loss": 1.2282,
      "step": 385
    },
    {
      "epoch": 0.042711641660278174,
      "grad_norm": 1.499393343925476,
      "learning_rate": 0.00019788224086762175,
      "loss": 1.3416,
      "step": 390
    },
    {
      "epoch": 0.043259226809768916,
      "grad_norm": 1.805613398551941,
      "learning_rate": 0.0001978456014362657,
      "loss": 1.2455,
      "step": 395
    },
    {
      "epoch": 0.043806811959259666,
      "grad_norm": 1.2791459560394287,
      "learning_rate": 0.0001978089620049097,
      "loss": 1.3586,
      "step": 400
    },
    {
      "epoch": 0.04435439710875041,
      "grad_norm": 1.6104570627212524,
      "learning_rate": 0.00019777232257355367,
      "loss": 1.3619,
      "step": 405
    },
    {
      "epoch": 0.04490198225824116,
      "grad_norm": 1.4956430196762085,
      "learning_rate": 0.00019773568314219764,
      "loss": 1.3821,
      "step": 410
    },
    {
      "epoch": 0.0454495674077319,
      "grad_norm": 1.4602031707763672,
      "learning_rate": 0.00019769904371084163,
      "loss": 1.388,
      "step": 415
    },
    {
      "epoch": 0.04599715255722265,
      "grad_norm": 1.4444836378097534,
      "learning_rate": 0.0001976624042794856,
      "loss": 1.3331,
      "step": 420
    },
    {
      "epoch": 0.04654473770671339,
      "grad_norm": 1.2093356847763062,
      "learning_rate": 0.00019762576484812957,
      "loss": 1.3507,
      "step": 425
    },
    {
      "epoch": 0.04709232285620414,
      "grad_norm": 1.3870060443878174,
      "learning_rate": 0.00019758912541677356,
      "loss": 1.1412,
      "step": 430
    },
    {
      "epoch": 0.047639908005694884,
      "grad_norm": 1.6465176343917847,
      "learning_rate": 0.0001975524859854175,
      "loss": 1.3192,
      "step": 435
    },
    {
      "epoch": 0.04818749315518563,
      "grad_norm": 1.332849144935608,
      "learning_rate": 0.0001975158465540615,
      "loss": 1.4218,
      "step": 440
    },
    {
      "epoch": 0.048735078304676376,
      "grad_norm": 1.3968337774276733,
      "learning_rate": 0.00019747920712270546,
      "loss": 1.3833,
      "step": 445
    },
    {
      "epoch": 0.049282663454167125,
      "grad_norm": 1.381325602531433,
      "learning_rate": 0.00019744256769134943,
      "loss": 1.4744,
      "step": 450
    },
    {
      "epoch": 0.04983024860365787,
      "grad_norm": 1.6737687587738037,
      "learning_rate": 0.00019740592825999342,
      "loss": 1.2778,
      "step": 455
    },
    {
      "epoch": 0.05037783375314862,
      "grad_norm": 1.810552954673767,
      "learning_rate": 0.00019736928882863739,
      "loss": 1.6206,
      "step": 460
    },
    {
      "epoch": 0.05092541890263936,
      "grad_norm": 1.3219302892684937,
      "learning_rate": 0.00019733264939728135,
      "loss": 1.0672,
      "step": 465
    },
    {
      "epoch": 0.05147300405213011,
      "grad_norm": 1.4030159711837769,
      "learning_rate": 0.00019729600996592535,
      "loss": 1.0988,
      "step": 470
    },
    {
      "epoch": 0.05202058920162085,
      "grad_norm": 1.3298685550689697,
      "learning_rate": 0.0001972593705345693,
      "loss": 1.231,
      "step": 475
    },
    {
      "epoch": 0.0525681743511116,
      "grad_norm": 1.0235271453857422,
      "learning_rate": 0.0001972227311032133,
      "loss": 1.3979,
      "step": 480
    },
    {
      "epoch": 0.05311575950060234,
      "grad_norm": 1.2157551050186157,
      "learning_rate": 0.00019718609167185727,
      "loss": 1.3663,
      "step": 485
    },
    {
      "epoch": 0.05366334465009309,
      "grad_norm": 1.264522910118103,
      "learning_rate": 0.00019714945224050124,
      "loss": 1.2099,
      "step": 490
    },
    {
      "epoch": 0.054210929799583835,
      "grad_norm": 1.262156367301941,
      "learning_rate": 0.00019711281280914523,
      "loss": 1.3302,
      "step": 495
    },
    {
      "epoch": 0.054758514949074584,
      "grad_norm": 1.6070435047149658,
      "learning_rate": 0.0001970761733777892,
      "loss": 1.1682,
      "step": 500
    }
  ],
  "logging_steps": 5,
  "max_steps": 27393,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.2218323887286272e+16,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
