{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration - WAD Dataset\n",
    "## Khám phá dữ liệu WAD_Images cho Vision-Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from datasets import load_dataset\n",
    "from collections import defaultdict, Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import io\n",
    "import tarfile\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load metadata\n",
    "print(\"Loading metadata...\")\n",
    "metadata = load_dataset(\n",
    "    \"minhdang0901/WAD_Images\",\n",
    "    data_files={\n",
    "        \"train\": \"train.json\",\n",
    "        \"test\": \"test_alter.json\"\n",
    "    }\n",
    ")\n",
    "\n",
    "print(f\"Train samples: {len(metadata['train'])}\")\n",
    "print(f\"Test samples: {len(metadata['test'])}\")\n",
    "\n",
    "# Show sample\n",
    "sample = metadata['train'][0]\n",
    "print(\"\\nSample structure:\")\n",
    "for key in sample.keys():\n",
    "    print(f\"  - {key}: {type(sample[key]).__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Analyze Metadata Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract metadata fields\n",
    "train_data = metadata['train']\n",
    "\n",
    "area_types = [s['area_type'] for s in train_data]\n",
    "weather_conditions = [s['weather_condition'] for s in train_data]\n",
    "traffic_flow = [s['traffic_flow_rating'] for s in train_data]\n",
    "\n",
    "# Create subplots\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Area type distribution\n",
    "area_counts = Counter(area_types)\n",
    "axes[0].bar(area_counts.keys(), area_counts.values())\n",
    "axes[0].set_title('Area Type Distribution', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Area Type')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Weather distribution\n",
    "weather_counts = Counter(weather_conditions)\n",
    "axes[1].bar(weather_counts.keys(), weather_counts.values(), color='orange')\n",
    "axes[1].set_title('Weather Condition Distribution', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Weather')\n",
    "axes[1].set_ylabel('Count')\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Traffic distribution\n",
    "traffic_counts = Counter(traffic_flow)\n",
    "axes[2].bar(traffic_counts.keys(), traffic_counts.values(), color='green')\n",
    "axes[2].set_title('Traffic Flow Distribution', fontsize=14, fontweight='bold')\n",
    "axes[2].set_xlabel('Traffic Level')\n",
    "axes[2].set_ylabel('Count')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../experiments/results/metadata_distribution.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Analyze BBox Annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load bbox data\n",
    "print(\"Loading bbox annotations...\")\n",
    "bbox_dataset = load_dataset(\n",
    "    \"minhdang0901/WAD_Images\",\n",
    "    data_files=\"all_bboxes.jsonl\",\n",
    "    split=\"train\"\n",
    ")\n",
    "\n",
    "print(f\"Total bbox entries: {len(bbox_dataset)}\")\n",
    "\n",
    "# Analyze object labels\n",
    "labels = [entry['label'] for entry in bbox_dataset]\n",
    "label_counts = Counter(labels)\n",
    "\n",
    "# Plot top 20 objects\n",
    "top_objects = dict(label_counts.most_common(20))\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.barh(list(top_objects.keys()), list(top_objects.values()))\n",
    "plt.xlabel('Count', fontsize=12)\n",
    "plt.ylabel('Object Label', fontsize=12)\n",
    "plt.title('Top 20 Detected Objects', fontsize=14, fontweight='bold')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.savefig('../experiments/results/top_objects.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nTotal unique objects: {len(label_counts)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualize Sample Images with BBoxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell requires frame_index.pkl to be built first\n",
    "# Run: python scripts/build_frame_index.py\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "index_file = \"../wad_dataset/frame_index.pkl\"\n",
    "\n",
    "if os.path.exists(index_file):\n",
    "    with open(index_file, 'rb') as f:\n",
    "        frame_index = pickle.load(f)\n",
    "    \n",
    "    # Load and display a sample image\n",
    "    sample = metadata['train'][0]\n",
    "    frame_path = sample['frame_path']\n",
    "    \n",
    "    if frame_path in frame_index:\n",
    "        frame_ids = sorted(frame_index[frame_path].keys())\n",
    "        first_frame_id = frame_ids[0]\n",
    "        \n",
    "        frame_info = frame_index[frame_path][first_frame_id]\n",
    "        \n",
    "        # Load image\n",
    "        with tarfile.open(frame_info['shard'], 'r') as tar:\n",
    "            member = tar.getmember(frame_info['tar_path'])\n",
    "            file_obj = tar.extractfile(member)\n",
    "            img = Image.open(io.BytesIO(file_obj.read()))\n",
    "        \n",
    "        plt.figure(figsize=(10, 8))\n",
    "        plt.imshow(img)\n",
    "        plt.title(f'Sample Image: {frame_path}/{first_frame_id}', fontsize=14)\n",
    "        plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "else:\n",
    "    print(\"Frame index not found. Run: python scripts/build_frame_index.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Instruction Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze instruction lengths\n",
    "instruction_lengths = []\n",
    "\n",
    "for sample in train_data:\n",
    "    if 'alter' in sample and sample['alter']:\n",
    "        instruction_lengths.append(len(sample['alter'].split()))\n",
    "    elif 'QA' in sample and isinstance(sample['QA'], dict):\n",
    "        if 'A' in sample['QA']:\n",
    "            instruction_lengths.append(len(sample['QA']['A'].split()))\n",
    "\n",
    "# Plot distribution\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(instruction_lengths, bins=30, edgecolor='black')\n",
    "plt.xlabel('Number of Words', fontsize=12)\n",
    "plt.ylabel('Frequency', fontsize=12)\n",
    "plt.title('Instruction Length Distribution', fontsize=14, fontweight='bold')\n",
    "plt.axvline(np.mean(instruction_lengths), color='red', linestyle='--', label=f'Mean: {np.mean(instruction_lengths):.1f}')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('../experiments/results/instruction_length_dist.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Instruction statistics:\")\n",
    "print(f\"  Mean: {np.mean(instruction_lengths):.2f} words\")\n",
    "print(f\"  Median: {np.median(instruction_lengths):.2f} words\")\n",
    "print(f\"  Min: {np.min(instruction_lengths)} words\")\n",
    "print(f\"  Max: {np.max(instruction_lengths)} words\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = {\n",
    "    'Total Train Samples': len(metadata['train']),\n",
    "    'Total Test Samples': len(metadata['test']),\n",
    "    'Total BBox Annotations': len(bbox_dataset),\n",
    "    'Unique Object Types': len(label_counts),\n",
    "    'Unique Area Types': len(area_counts),\n",
    "    'Unique Weather Conditions': len(weather_counts),\n",
    "    'Avg Instruction Length': f\"{np.mean(instruction_lengths):.2f} words\"\n",
    "}\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DATASET SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for key, value in summary.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Save summary\n",
    "import json\n",
    "with open('../experiments/results/data_summary.json', 'w') as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "print(\"\\n✓ Summary saved to experiments/results/data_summary.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
