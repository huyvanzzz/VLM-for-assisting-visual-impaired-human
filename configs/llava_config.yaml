# ===== LLAVA-ONEVISION CONFIG =====
experiment:
  name: "wad_llava_onevision_training"
  version: "1.0"
  description: "LLaVA-OneVision for Blind Navigation"
  tags: ["llava", "onevision", "navigation", "wad"]

# ===== MODEL SELECTION =====
model:
  architecture: "llava"
  name: "llava-hf/llava-onevision-qwen2-0.5b-ov-hf"
  
  # LoRA config
  lora:
    enabled: true
    r: 16
    alpha: 16
    dropout: 0.05
    target_modules: 
      - "q_proj"
      - "k_proj"
      - "v_proj"
      - "o_proj"
      - "gate_proj"
      - "up_proj"
      - "down_proj"
  
  # Quantization
  quantization:
    enabled: true
    bits: 4
    type: "nf4"
    double_quant: true
  
  # Vision config
  vision:
    freeze_encoder: true
    image_size: [384, 384]
    max_tiles: 1

# ===== DATASET =====
data:
  name: "minhdang0901/WAD_Images"
  num_frames: 1
  train_split: 0.9
  seed: 42
  max_samples: null  # null = use all data

# ===== TRAINING =====
training:
  output_dir: "./outputs/llava_onevision"
  num_epochs: 3
  batch_size: 1
  gradient_accumulation_steps: 2
  learning_rate: 2e-4
  warmup_steps: 100
  weight_decay: 0.01
  fp16: true
  gradient_checkpointing: true
  
  # Optimizer
  optimizer: "paged_adamw_8bit"
  lr_scheduler: "cosine"
  
  # Logging
  logging_steps: 5
  evaluation_strategy: "steps"
  eval_steps: 500
  save_steps: 500
  save_total_limit: 2
  
  # Early stopping
  early_stopping:
    enabled: false
    patience: 3
    metric: "eval_loss"

# ===== EVALUATION =====
evaluation:
  metrics:
    - "exact_match"
    - "location_accuracy"
    - "weather_accuracy"
    - "traffic_accuracy"
    - "scene_accuracy"
    - "instruction_accuracy"
  batch_size: 2

# ===== HARDWARE =====
hardware:
  device: "cuda"
  num_workers: 0
  pin_memory: false
  cuda_alloc_conf: "expandable_segments:True,max_split_size_mb:128"

# ===== EXPERIMENT TRACKING =====
tracking:
  enabled: true
  backend: "mlflow"  # Options: mlflow, wandb, tensorboard, none
  project_name: "wad-vlm"
  log_model: true
  log_frequency: 10