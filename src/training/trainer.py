from transformers import Trainer, TrainingArguments
from typing import Dict, Any
import yaml
import torch
from tqdm.auto import tqdm
import gc
import os
import warnings

class VLMTrainer:
    """High-level training orchestration"""
    
    def __init__(self, config_path: str):
        warnings.filterwarnings('ignore', message='.*Unused or unrecognized kwargs.*')

        os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'
        with open(config_path, 'r') as f:
            self.config = yaml.safe_load(f)
        
        self.model = None
        self.trainer = None
        self.results = {}
        self.pbar = None  # Progress bar
    
    def setup(self):
        """Setup model, data, trainer"""
        self._clear_memory()

        from ..models.model_registry import build_model
        from ..data.wad_dataset import build_dataset
        from .callbacks import MemoryOptimizationCallback, ExperimentTrackingCallback
        from ..data.data_collator import VLMDataCollator
        
        # T·∫°o progress bar cho setup
        setup_steps = ["Building model", "Building dataset", "Creating trainer"]
        with tqdm(total=len(setup_steps), desc="Setup Progress") as pbar:
            # Build model
            pbar.set_description("Building model...")
            vlm = build_model(self.config)
            self.model = vlm.model
            print("\n" + "="*40)
            print("ü©∫ [SANITY CHECK] Ki·ªÉm tra c·∫•u h√¨nh Model")
            try:
                # 1. Check Config (Ch·ªâ in th√¥ng s·ªë quan tr·ªçng, kh√¥ng in c·∫£ c·ª•m ƒë·ªÉ tr√°nh l·ªói JSON)
                if hasattr(self.model.config, "vision_config"):
                    vc = self.model.config.vision_config
                    # L·∫•y th√¥ng s·ªë an to√†n
                    hidden_size = getattr(vc, 'hidden_size', 'N/A')
                    patch_size = getattr(vc, 'patch_size', 14) # M·∫∑c ƒë·ªãnh 14 n·∫øu ko t√¨m th·∫•y
                    image_size = getattr(vc, 'image_size', 336) # M·∫∑c ƒë·ªãnh 336
                    
                    print(f" - Vision Params: Size={image_size}, Patch={patch_size}, Hidden={hidden_size}")
                else:
                    print(" - Kh√¥ng t√¨m th·∫•y vision_config (Model l·∫°?)")
                    vc = None

                # 2. Check Th·ª±c t·∫ø (Ch·∫°y th·ª≠ 1 ·∫£nh r·ªóng)
                print(" - ƒêang ch·∫°y th·ª≠ Vision Tower ƒë·ªÉ ƒë·∫øm token...")
                
                # T√¨m Vision Tower
                tower = None
                if hasattr(self.model, "vision_tower"):
                    tower = self.model.vision_tower
                elif hasattr(self.model, "model") and hasattr(self.model.model, "vision_tower"):
                    tower = self.model.model.vision_tower
                
                if tower is not None:
                    # T·∫°o ·∫£nh gi·∫£ ƒë√∫ng device/dtype c·ªßa model
                    device = self.model.device
                    dtype = self.model.dtype if self.model.dtype not in [torch.float32, torch.float16, torch.bfloat16] else torch.float16 # Fallback an to√†n
                    
                    # L·∫•y image size th·ª±c t·∫ø
                    img_s = image_size if isinstance(image_size, int) else 336
                    
                    # T·∫°o input
                    dummy_pixel = torch.zeros(1, 3, img_s, img_s).to(device)
                    # Cast v·ªÅ ƒë√∫ng ki·ªÉu d·ªØ li·ªáu model ƒëang d√πng
                    dummy_pixel = dummy_pixel.to(dtype=self.model.dtype)

                    with torch.no_grad():
                        # M·ªôt s·ªë model output ra tuple, m·ªôt s·ªë ra tensor lu√¥n
                        outputs = tower(dummy_pixel)
                        
                        # X·ª≠ l√Ω output ƒë·ªÉ l·∫•y features cu·ªëi c√πng
                        if isinstance(outputs, (tuple, list)):
                            features = outputs[-1] # Th∆∞·ªùng hidden states n·∫±m cu·ªëi ho·∫∑c ƒë·∫ßu
                            # N·∫øu v·∫´n l√† tuple (hidden_states), l·∫•y c√°i cu·ªëi
                            if isinstance(features, (tuple, list)):
                                features = features[-1]
                        elif hasattr(outputs, "last_hidden_state"):
                             features = outputs.last_hidden_state
                        else:
                            features = outputs

                    # ƒê·∫øm s·ªë token
                    # Features shape: [Batch, Num_Tokens, Hidden]
                    real_tokens = features.shape[1]
                    
                    # T√≠nh to√°n l√Ω thuy·∫øt
                    grid_w = img_s // patch_size
                    expected_tokens = grid_w * grid_w
                    
                    print(f"   + L√Ω thuy·∫øt (Grid {grid_w}x{grid_w}): {expected_tokens}")
                    print(f"   + Th·ª±c t·∫ø Vision tr·∫£ v·ªÅ: {real_tokens}")
                    
                    diff = real_tokens - expected_tokens
                    if diff == 1:
                        print(f" -> üö® K·∫æT LU·∫¨N: Model c√≥ th√™m 1 token (CLS/Global). CODE FIX C·∫¶N ƒê∆Ø·ª¢C B·∫¨T!")
                    elif diff == 0:
                        print(f" -> ‚úÖ K·∫æT LU·∫¨N: S·ªë l∆∞·ª£ng kh·ªõp (Kh√¥ng c√≥ CLS).")
                    else:
                         print(f" -> ‚ö†Ô∏è L·ªách {diff} token (C√≥ th·ªÉ do ki·∫øn tr√∫c ƒë·∫∑c bi·ªát).")
                else:
                    print(" - Kh√¥ng t√¨m th·∫•y module vision_tower ƒë·ªÉ test.")

            except Exception as e:
                print(f" - (Check th·∫•t b·∫°i do l·ªói code check: {e})")
                # In traceback ƒë·ªÉ debug n·∫øu c·∫ßn
                # import traceback
                # traceback.print_exc()
            print("="*40 + "\n")
            pbar.update(1)
            
            # Build dataset
            pbar.set_description("Building dataset...")
            train_dataset, eval_dataset = build_dataset(
                self.config,
                vlm.processor,
                vlm.tokenizer
            )
            pbar.update(1)
            
            # Training arguments
            pbar.set_description("Creating trainer...")
            training_args = TrainingArguments(
                output_dir=self.config['training']['output_dir'],
                num_train_epochs=self.config['training']['num_epochs'],
                per_device_train_batch_size=self.config['training']['batch_size'],
                gradient_accumulation_steps=self.config['training']['gradient_accumulation_steps'],
                learning_rate=float(self.config['training']['learning_rate']),
                warmup_steps=int(self.config['training']['warmup_steps']),
                weight_decay=float(self.config['training']['weight_decay']),
                fp16=self.config['training']['fp16'],
                gradient_checkpointing=self.config['training']['gradient_checkpointing'],
                logging_steps=self.config['training']['logging_steps'],
                eval_steps=self.config['training']['eval_steps'],
                save_steps=self.config['training']['save_steps'],
                save_total_limit=self.config['training']['save_total_limit'],
                remove_unused_columns=False,
                dataloader_pin_memory=self.config['hardware']['pin_memory'],
                dataloader_num_workers=self.config['hardware']['num_workers'],
                report_to="none",
                optim=self.config['training']['optimizer'],
                disable_tqdm=False,  # B·∫≠t tqdm c·ªßa Trainer
            )
            
            data_collator = VLMDataCollator(tokenizer=vlm.tokenizer)
                
            # Callbacks
            callbacks = [
                MemoryOptimizationCallback(
                    clear_cache_steps=25,  # C√≥ th·ªÉ gi·∫£m xu·ªëng 10 n·∫øu v·∫´n OOM
                    log_memory_steps=10
                ),
            ]
            
            if self.config['tracking']['enabled']:
                callbacks.append(ExperimentTrackingCallback(self.config))
            
            # Create trainer
            self.trainer = Trainer(
                model=self.model,
                args=training_args,
                train_dataset=train_dataset,
                eval_dataset=eval_dataset,
                tokenizer=vlm.tokenizer,
                data_collator=data_collator,
                callbacks=callbacks
            )
            pbar.update(1)
        
        print("‚úì Setup complete!")
    
    def train(self):
        """Run training"""
        print("\n" + "="*80)
        print("STARTING TRAINING")
        print("="*80 + "\n")
        
        self._clear_memory() 
        # Trainer ƒë√£ c√≥ tqdm built-in, ch·ªâ c·∫ßn ƒë·∫£m b·∫£o disable_tqdm=False
        self.trainer.train()
        
        print("\n‚úì Training complete!")
        self._clear_memory()

    def evaluate(self):
        """Run evaluation"""
        print("\n" + "="*80)
        print("EVALUATION")
        print("="*80 + "\n")
        self._clear_memory()
        results = self.trainer.evaluate()
        self.results = results
        
        print(results)
        self._clear_memory() 
        return results
    
    def save(self, output_path: str):

        self._clear_memory()
        """Save model"""
        print(f"\nSaving model to {output_path}...")
        with tqdm(total=1, desc="Saving model") as pbar:
            self.trainer.save_model(output_path)
            pbar.update(1)
        print(f"‚úì Model saved to {output_path}")
        self._clear_memory()
    def _clear_memory(self):
        """Clear GPU and CPU memory"""
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
            torch.cuda.synchronize()
        gc.collect()